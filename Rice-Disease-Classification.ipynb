{"cells":[{"cell_type":"markdown","metadata":{"id":"NgH-ktSf3ZKY"},"source":["# Microsoft challenge"]},{"cell_type":"markdown","metadata":{"id":"XLeAIa0N13lX"},"source":["## Set ix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8aUN1ju25U0c"},"outputs":[],"source":["ix = 0"]},{"cell_type":"markdown","metadata":{"id":"V3_gsrJlqThn"},"source":["## Loading data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36269,"status":"ok","timestamp":1660493720267,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"},"user_tz":-120},"id":"xRIfHWFvE8hv","outputId":"890bad17-f2f3-421b-fc9e-68c863a8e461"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7YFeYxqDKyP"},"outputs":[],"source":["#copy data and unzip\n","!mkdir images\n","!unzip /content/drive/MyDrive/Microsoft_challenge/Images.zip -d ./images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGKZyGdliE7e"},"outputs":[],"source":["#copy annotation & submission files\n","!cp /content/drive/MyDrive/Microsoft_challenge/Train.csv ./\n","!cp /content/drive/MyDrive/Microsoft_challenge/Test.csv ./\n","!cp /content/drive/MyDrive/Microsoft_challenge/SampleSubmission.csv ./"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660493742411,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"},"user_tz":-120},"id":"-TPkBbHum59b","outputId":"2476ee35-bcf5-484d-e408-9933a53c7d6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(7630, 3815)"]},"metadata":{},"execution_count":5}],"source":["#check length of images\n","import glob\n","len(glob.glob('./images/*')),len(glob.glob('./images/*_rgn*'))"]},{"cell_type":"markdown","metadata":{"id":"EmLWupfkXj05"},"source":["## Defining model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mez5_Ws79IQ_"},"outputs":[],"source":["!pip install --upgrade torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tGjUzovLbOND"},"outputs":[],"source":["!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UUpJCzZVcwR0"},"outputs":[],"source":["#imports\n","import cv2\n","import tqdm\n","import random\n","import glob\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sb\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn, optim, Tensor\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from torchvision import models\n","import timm\n","\n","def set_seed(seed,data_seed):\n","  torch.manual_seed(seed)\n","  torch.cuda.manual_seed(seed)\n","  torch.cuda.manual_seed_all(seed)\n","  np.random.seed(seed)\n","  random.seed(seed)\n","  torch.backends.cudnn.benchmark = False\n","  torch.backends.cudnn.deterministic = True\n","  g = torch.Generator()\n","  g.manual_seed(data_seed)\n","  os.environ['PYTHONHASHSEED'] = str(seed)\n","  return g"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nHtSf_eP49HT"},"outputs":[],"source":["df = pd.read_csv('/content/drive/MyDrive/common/model_variants_df.csv')\n","entries = df.iloc[ix]\n","\n","lr = entries.lr\n","weight_decay = entries.wd\n","seed = int(entries.seed)\n","data_seed = int(entries.data_seed)\n","rgn = entries.RGN\n","extra_info = entries.extra_info\n","done = entries.done\n","model_name = entries.model_name\n","\n","if done:\n","  raise ValueError('Model is cancelled')\n","\n","img_size = (400,500)\n","if rgn:\n","  img_size = (400,400)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RtttirJnXGH9","executionInfo":{"status":"ok","timestamp":1660499296220,"user_tz":-120,"elapsed":30,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"}},"outputId":"0d8031cd-20fc-49d2-9c4b-a83e805204b9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["#define model\n","model_name_list = ['resnet_18','resnet_34','resnet_50','resnet_101','resnet_152',\n","                   'effnet_s','effnet_m','effnet_l',\n","                   'convnext_t','convnext_s','convnext_b','convnext_l',\n","                   'swin_t','swin_s','swin_b',\n","                   'deit3_s','deit3_b','deit3_l',\n","                   'coatLite_m','coatLite_t','coatLite_s',\n","                   'coat_m','coat_t']\n","\n","def initialize_model(full_name):\n","  is224 = False\n","  name,size = full_name.split('_')[0],full_name.split('_')[1]\n","\n","  if name == 'resnet':\n","    if size == '18':\n","      model = models.resnet18(pretrained=True)\n","      batch_size = 64\n","    elif size == '34':\n","      model = models.resnet34(pretrained=True)\n","      batch_size = 64\n","    elif size == '50':\n","      model = models.resnet50(pretrained=True)\n","      batch_size = 32\n","    elif size == '101':\n","      model = models.resnet101(pretrained=True)\n","      batch_size = 16\n","    elif size == '152':\n","      model = models.resnet152(pretrained=True)\n","      batch_size = 16\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=3)\n","\n","\n","  if name == 'effnet':\n","    if size == 's':\n","      model = models.efficientnet_v2_s(pretrained=True)\n","      batch_size = 16\n","    elif size == 'm':\n","      model = models.efficientnet_v2_m(pretrained=True)\n","      batch_size = 8\n","    elif size == 'l':\n","      model = models.efficientnet_v2_l(pretrained=True)\n","      batch_size = 4\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.classifier[1] = nn.Linear(in_features=model.classifier[1].in_features, out_features=3, bias=True)\n","\n","\n","  elif name == 'convnext':\n","    if size == 't':\n","      model = models.convnext_tiny(pretrained=True)\n","      batch_size = 16\n","    elif size == 's':\n","      model = models.convnext_small(pretrained=True)\n","      batch_size = 16\n","    elif size == 'b':\n","      model = models.convnext_base(pretrained=True)\n","      batch_size = 8\n","    elif size == 'l':\n","      model = models.convnext_large(pretrained=True)\n","      batch_size = 4\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.classifier[2] = nn.Linear(in_features=model.classifier[2].in_features, out_features=3, bias=True)\n","\n","\n","  elif name == 'swin':\n","    if size == 't':\n","      model = models.swin_t(weights=models.Swin_T_Weights.IMAGENET1K_V1)\n","      batch_size = 16\n","    elif size == 's':\n","      model = models.swin_s(weights=models.Swin_S_Weights.IMAGENET1K_V1)\n","      batch_size = 16\n","    elif size == 'b':\n","      model = models.swin_b(weights=models.Swin_B_Weights.IMAGENET1K_V1)\n","      batch_size = 8\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.head = nn.Linear(in_features=model.head.in_features, out_features=3, bias=True)\n","\n","\n","  elif name == 'deit3':\n","    is224 = True\n","    if size == 's':\n","      model = timm.create_model('deit3_small_patch16_224',pretrained=True)\n","      batch_size = 128\n","    elif size == 'b':\n","      model = timm.create_model('deit3_base_patch16_224',pretrained=True)\n","      batch_size = 64\n","    elif size == 'l':\n","      model = timm.create_model('deit3_large_patch16_224',pretrained=True)\n","      batch_size = 16\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.head = nn.Linear(in_features=model.head.in_features, out_features=3, bias=True)\n","\n","\n","  elif name == 'coatLite':\n","    if size == 'm':\n","      model = timm.create_model('coat_lite_mini',pretrained=True,img_size=img_size)\n","      batch_size = 32\n","    elif size == 't':\n","      model = timm.create_model('coat_lite_tiny',pretrained=True,img_size=img_size)\n","      batch_size = 32\n","    elif size == 's':\n","      model = timm.create_model('coat_lite_small',pretrained=True,img_size=img_size)\n","      batch_size = 16\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.head = nn.Linear(in_features=model.head.in_features, out_features=3, bias=True)\n","\n","\n","  elif name == 'coat':\n","    is224 = True\n","    if size == 'm':\n","      model = timm.create_model('coat_mini',pretrained=True)\n","      batch_size = 32\n","    elif size == 't':\n","      model = timm.create_model('coat_tiny',pretrained=True)\n","      batch_size = 32\n","    else:\n","      print(f'{full_name} is not implemented')\n","    model.head = nn.Linear(in_features=model.head.in_features, out_features=3, bias=True)\n","\n","\n","  if torch.cuda.is_available():\n","    model = model.cuda()\n","  return model,batch_size,is224\n","model,batch_size,is224 = initialize_model(model_name)"]},{"cell_type":"markdown","metadata":{"id":"xVcCRHyrXGHv"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Of2dcL5uXGH-"},"outputs":[],"source":["#defining data class\n","class data_set(Dataset):\n","    def __init__(self,is224,rgn,test=False):\n","        self.is224 = is224\n","        self.rgn = rgn\n","        #load data\n","        train_df = pd.read_csv('/content/Train.csv')\n","        test_df = pd.read_csv('/content/Test.csv')\n","\n","        start_ix = 0\n","        if rgn:\n","          start_ix = 1\n","\n","        if test:\n","          self.labels =  test_df['Image_id'].values[::2]\n","          self.images = test_df['Image_id'].values[start_ix::2]\n","\n","        else:\n","          self.labels =  train_df['Label'].replace({'blast':0,'brown':1,'healthy':2}).values[::2]\n","          self.images = train_df['Image_id'].values[start_ix::2]\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, index):\n","        image_path = './images/' + self.images[index]\n","        image = cv2.imread(image_path)\n","        if self.is224:\n","          image = cv2.resize(image,(224,224))\n","        elif self.rgn:\n","          image = cv2.resize(image,(400,400))\n","        image = image.transpose(2,0,1)\n","        label = self.labels[index]\n","        return image,label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gH1-Dej_fT6V","executionInfo":{"status":"ok","timestamp":1660502931237,"user_tz":-120,"elapsed":2938548,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"}},"outputId":"3b3803cb-2d64-4145-8bbf-e918929ce6cc"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["==================== SEED  9 ====================\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["---------- Epoch :1/30 ----------\n","learning rate:  0.0001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [01:51<00:00,  3.36s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss:  0.78773147\n","validation loss:  0.637476\n","---------- Epoch :2/30 ----------\n","learning rate:  0.0001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [01:39<00:00,  3.00s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss:  0.27677092\n","validation loss:  0.52599156\n","---------- Epoch :3/30 ----------\n","learning rate:  0.0001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [01:38<00:00,  2.99s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss:  0.07403968\n","validation loss:  0.5401815\n","---------- Epoch :4/30 ----------\n","learning rate:  0.0001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [01:38<00:00,  2.98s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss:  0.026700636\n","validation loss:  0.51563996\n","---------- Epoch :5/30 ----------\n","learning rate:  0.0001\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 33/33 [01:38<00:00,  2.97s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["train loss:  0.01142133\n","validation loss:  0.4762348\n","---------- Epoch :6/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:37<00:00,  2.96s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0070815883\n","validation loss:  0.5095187\n","---------- Epoch :7/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.97s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.005812891\n","validation loss:  0.5098127\n","---------- Epoch :8/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:37<00:00,  2.96s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0033738622\n","validation loss:  0.49925232\n","---------- Epoch :9/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:37<00:00,  2.96s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0029096757\n","validation loss:  0.5078765\n","---------- Epoch :10/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:37<00:00,  2.96s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0025030798\n","validation loss:  0.51994824\n","---------- Epoch :11/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:39<00:00,  3.01s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0020207951\n","validation loss:  0.5135454\n","---------- Epoch :12/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.97s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.001990409\n","validation loss:  0.51053923\n","---------- Epoch :13/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0016173666\n","validation loss:  0.51549715\n","---------- Epoch :14/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.99s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.001579777\n","validation loss:  0.5052712\n","---------- Epoch :15/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.001553243\n","validation loss:  0.50860316\n","---------- Epoch :16/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0011622055\n","validation loss:  0.51229405\n","---------- Epoch :17/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.00096960197\n","validation loss:  0.51488966\n","---------- Epoch :18/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:38<00:00,  2.98s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0010813789\n","validation loss:  0.53677386\n","---------- Epoch :19/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:39<00:00,  3.02s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0008462753\n","validation loss:  0.5228804\n","---------- Epoch :20/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0007896209\n","validation loss:  0.5248122\n","---------- Epoch :21/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.00084591645\n","validation loss:  0.5280893\n","---------- Epoch :22/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.00066808116\n","validation loss:  0.534764\n","---------- Epoch :23/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:42<00:00,  3.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0005656322\n","validation loss:  0.52916855\n","---------- Epoch :24/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.09s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.00061301485\n","validation loss:  0.5291526\n","---------- Epoch :25/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0009734258\n","validation loss:  0.5957371\n","---------- Epoch :26/30 ----------\n","learning rate:  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.07s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.00057731813\n","validation loss:  0.53952366\n","---------- Epoch :27/30 ----------\n","learning rate:  1e-05\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0005781056\n","validation loss:  0.5419378\n","---------- Epoch :28/30 ----------\n","learning rate:  1e-05\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:40<00:00,  3.05s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0003923218\n","validation loss:  0.53865504\n","---------- Epoch :29/30 ----------\n","learning rate:  1e-05\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.0006399151\n","validation loss:  0.55078083\n","---------- Epoch :30/30 ----------\n","learning rate:  1e-05\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 33/33 [01:41<00:00,  3.08s/it]\n"]},{"output_type":"stream","name":"stdout","text":["train loss:  0.00052865624\n","validation loss:  0.53762245\n","best-val 0.4762348\n"]}],"source":["#training (No CV - Multi-seed)\n","#hyper-parameters values\n","\n","#data_seeds = [0,1,9]\n","g = set_seed(seed,data_seed)\n","print('='*20,'SEED ',data_seed,'='*20)\n","model,batch_size,is224 = initialize_model(model_name)\n","\n","num_epochs = 30\n","\n","#dataloader, optimizer, scheduler, cost function\n","optimizer = optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience = 2,factor=0.1)\n","\n","DataSet = data_set(is224,rgn)\n","train_DataSet, val_DataSet = random_split(DataSet,[2136,534],generator=g)\n","train_loader = DataLoader(train_DataSet, batch_size=batch_size, shuffle=True, drop_last=True, generator=g)\n","val_loader = DataLoader(val_DataSet, batch_size=batch_size, shuffle=True, drop_last=False, generator=g)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","#training loop\n","train_loss_epochs = []\n","val_loss_epochs = []\n","\n","for epoch in range(0,num_epochs):\n","  print('-'*10,f\"Epoch :{epoch+1}/{num_epochs}\",'-'*10)\n","  print('learning rate: ',optimizer.param_groups[0][\"lr\"])\n","\n","  #train\n","  losses=[]\n","  model.train()\n","  for imgs,labels in tqdm.tqdm(train_loader):\n","    if torch.cuda.is_available():\n","      imgs = imgs.cuda()\n","      labels = labels.cuda()\n","    #forward\n","    preds = model(imgs.float())\n","    #loss and backward\n","    optimizer.zero_grad()\n","    loss = loss_fn(preds,labels)\n","    loss.backward()\n","    optimizer.step()\n","    losses.append(loss.detach().cpu())\n","  avg_loss = np.mean(losses)\n","  print('train loss: ',avg_loss)\n","  train_loss_epochs.append(avg_loss)\n","  scheduler.step(avg_loss)\n","\n","  #validation\n","  val_losses=[]\n","  model.eval()\n","  with torch.no_grad():\n","    for imgs,labels in val_loader:\n","      if torch.cuda.is_available():\n","        imgs = imgs.cuda()\n","        labels = labels.cuda()\n","      preds = model(imgs.float())\n","      val_loss = loss_fn(preds,labels)\n","      val_losses.append(val_loss.detach().cpu())\n","  val_losses[-1] = val_losses[-1]*len(preds)/batch_size\n","  avg_val_loss = np.mean(val_losses)\n","  print('validation loss: ',avg_val_loss)\n","  val_loss_epochs.append(avg_val_loss)\n","\n","  #save best model\n","  if np.sum(avg_val_loss < np.array(val_loss_epochs))==len(val_loss_epochs)-1 :\n","    checkpoint_dict = {'model':model.state_dict()}\n","    torch.save(checkpoint_dict, f'best_model-{data_seed}.pth')\n","\n","best_epoch = np.argmin(val_loss_epochs)\n","print('best-val',val_loss_epochs[best_epoch])\n"]},{"cell_type":"markdown","metadata":{"id":"clFW6Bk9Ap2M"},"source":["## Analyze results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"923Ctrkpf2lV","executionInfo":{"status":"ok","timestamp":1660502953085,"user_tz":-120,"elapsed":21861,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"}},"outputId":"7ab44764-85ce-4c5e-b49b-51f0bf42028c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["validation loss:  0.47623476\n","validation accuracy:  84.08239700374533\n"]}],"source":["\n","#re-validate and test\n","#reload model\n","g = set_seed(seed,data_seed)\n","model,_,_ = initialize_model(model_name)\n","checkpoint_dict = torch.load(f'best_model-{data_seed}.pth')\n","model.load_state_dict(checkpoint_dict['model'])\n","\n","#re-validate\n","DataSet = data_set(is224,rgn)\n","train_DataSet, val_DataSet = random_split(DataSet,[2136,534], generator=g)\n","train_loader = DataLoader(train_DataSet, batch_size=batch_size, shuffle=True, drop_last=True, generator=g)\n","val_loader = DataLoader(val_DataSet, batch_size=batch_size, shuffle=True, drop_last=False, generator=g)\n","\n","val_losses=[]\n","tot_preds=[]\n","tot_labels=[]\n","preds_values=[]\n","true_preds_tot = 0\n","val_len_data = val_DataSet.__len__()\n","\n","model.eval()\n","with torch.no_grad():\n","  for imgs,labels in val_loader:\n","    if torch.cuda.is_available():\n","      imgs = imgs.cuda()\n","      labels = labels.cuda()\n","    preds = model(imgs.float())\n","    preds_values.extend(preds.detach().cpu().numpy())\n","    tot_preds.extend(torch.max(preds,axis=1).indices.detach().cpu().numpy().tolist())\n","    tot_labels.extend(labels.detach().cpu().numpy().tolist())\n","    val_loss = loss_fn(preds,labels)\n","    val_losses.append(val_loss.detach().cpu())\n","    true_preds = (torch.max(preds,axis=1).indices == labels).sum()\n","    true_preds_tot += true_preds\n","val_losses[-1] = val_losses[-1]*len(preds)/batch_size\n","avg_val_loss = np.mean(val_losses)\n","val_acc = 100*(true_preds_tot.cpu().numpy()/val_len_data)\n","\n","#confusion matrix\n","cf_matrix = confusion_matrix(tot_preds, tot_labels)\n","df_cm = pd.DataFrame(cf_matrix, index = ['blast','brown','healthy'],\n","                    columns = ['blast','brown','healthy'])\n","sb.heatmap(df_cm, annot=True,fmt='.3g');\n","plt.show()\n","print('validation loss: ',avg_val_loss)\n","print('validation accuracy: ',val_acc)\n"]},{"cell_type":"markdown","metadata":{"id":"wmBQ4CSB1688"},"source":["## Compare"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoO4FGhcthAA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660502956737,"user_tz":-120,"elapsed":3662,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"}},"outputId":"3c273e03-fe51-4b12-e8a3-f0d50514734e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LbF1KY6T1rMe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660502956738,"user_tz":-120,"elapsed":7,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"}},"outputId":"17ddd508-089e-4f9f-c58f-d284fb1589e7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}],"source":["#save some info for comparison\n","df = pd.read_csv('/content/drive/MyDrive/common/model_variants_df.csv')\n","df['train_score'].iloc[ix] = train_loss_epochs[-1]\n","df['last_val_score'].iloc[ix] = np.sort(val_loss_epochs)[1:6].mean()\n","df['best_val_score'].iloc[ix] = val_loss_epochs[best_epoch]\n","df['best_val_acc'].iloc[ix] = val_acc\n","df['done'].iloc[ix] = True\n","\n","rgn_string = ''\n","if rgn:\n","  rgn_string = '_rgn'\n","if np.isnan(extra_info):\n"," extra_info = ''\n","np.save('/content/drive/MyDrive/Microsoft_challenge/results/'+model_name+extra_info+'_'+str(data_seed)+rgn_string+'_val_preds.npy',preds_values)\n","df.to_csv('/content/drive/MyDrive/common/model_variants_df.csv', index = False)\n"]},{"cell_type":"markdown","metadata":{"id":"5jBLY4PGAvFa"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecDRt1Rw-zIX"},"outputs":[],"source":["#test\n","ss_df = pd.read_csv('/content/SampleSubmission.csv')\n","\n","test_DataSet = data_set(is224,rgn,test=True)\n","test_loader = DataLoader(test_DataSet, batch_size=batch_size)\n","\n","checkpoint_dict = torch.load(f'best_model-{data_seed}.pth')\n","model.load_state_dict(checkpoint_dict['model'])\n","\n","model.eval()\n","softmax = nn.Softmax(dim=1)\n","with torch.no_grad():\n","  for imgs,labels in test_loader:\n","    if torch.cuda.is_available():\n","      imgs = imgs.cuda()\n","    preds = model(imgs.float())\n","    preds = softmax(preds).cpu().numpy()\n","\n","    for i,label in enumerate(labels):\n","      ss_df.loc[ss_df.Image_id==label,['blast','brown','healthy']] = preds[i]\n","ss_df.to_csv('/content/drive/MyDrive/Microsoft_challenge/results/'+model_name+extra_info+rgn_string+f'_subm-{data_seed}.csv', index = False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R1lV5BsTQMn3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660503003728,"user_tz":-120,"elapsed":40,"user":{"displayName":"sdsdds sddsff","userId":"00084634742267653314"}},"outputId":"27914785-9125-4ed0-fe03-0fc663570684"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Image_id     blast     brown   healthy\n","0  id_00vl5wvxq3.jpg  0.996923  0.002602  0.000475\n","1  id_01hu05mtch.jpg  0.098114  0.836526  0.065360\n","2  id_030ln10ewn.jpg  0.983165  0.014047  0.002789\n","3  id_03z57m8xht.jpg  0.998406  0.000097  0.001496\n","4  id_04ngep1w4b.jpg  0.998432  0.000411  0.001157"],"text/html":["\n","  <div id=\"df-bed2a00a-693a-4ecf-b248-4e53ac40a83c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image_id</th>\n","      <th>blast</th>\n","      <th>brown</th>\n","      <th>healthy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>id_00vl5wvxq3.jpg</td>\n","      <td>0.996923</td>\n","      <td>0.002602</td>\n","      <td>0.000475</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>id_01hu05mtch.jpg</td>\n","      <td>0.098114</td>\n","      <td>0.836526</td>\n","      <td>0.065360</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>id_030ln10ewn.jpg</td>\n","      <td>0.983165</td>\n","      <td>0.014047</td>\n","      <td>0.002789</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>id_03z57m8xht.jpg</td>\n","      <td>0.998406</td>\n","      <td>0.000097</td>\n","      <td>0.001496</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>id_04ngep1w4b.jpg</td>\n","      <td>0.998432</td>\n","      <td>0.000411</td>\n","      <td>0.001157</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bed2a00a-693a-4ecf-b248-4e53ac40a83c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bed2a00a-693a-4ecf-b248-4e53ac40a83c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bed2a00a-693a-4ecf-b248-4e53ac40a83c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}],"source":["ss_df.head()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["V3_gsrJlqThn","clFW6Bk9Ap2M","wmBQ4CSB1688"],"provenance":[],"authorship_tag":"ABX9TyO/ytrCzxVideoVJ5vxWsIH"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}